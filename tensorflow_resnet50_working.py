# -*- coding: utf-8 -*-
"""Tensorflow_ResNet50_Working.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uiWkdHC-uG3hrrj_Kb6rElIVYn4bi5bn
"""

import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random

tf.__version__

model = tf.keras.applications.ResNet50(weights='imagenet')

base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)
print(base_model.summary())

for i, layer in enumerate(base_model.layers):
  print(i, layer.name)

x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)

x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
preds = tf.keras.layers.Dense(9, activation ='softmax')(x)

model = tf.keras.models.Model(inputs=base_model.input, outputs=preds)
print(model.summary())

for i, layer in enumerate(model.layers):
  print(i, layer.name)

for layer in model.layers[:175]:
  layer.trainable = False

for layer in model.layers[175:]:
  layer.trainable = True

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)

from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive')

!cp "/content/drive/My Drive/SkinDataset/Skin_dataset.zip" "Skin_dataset.zip"

!unzip Skin_dataset.zip

train_generator = train_datagen.flow_from_directory('/content/New_Dataset/train', 
                                                   target_size = (224, 224),
                                                   color_mode = 'rgb',
                                                   batch_size = 32,
                                                   class_mode = 'categorical',
                                                   shuffle = True)

model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit_generator(generator = train_generator, steps_per_epoch=train_generator.n//train_generator.batch_size, epochs = 12)



acc = history.history['accuracy']
loss = history.history['loss']

plt.figure()
plt.plot(acc, label='Training Accuracy')
plt.ylabel('Accuracy')
plt.title('Training Accuracy')

plt.figure()

plt.plot(loss, label='Training Loss')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.xlabel('epoch')
plt.show()

!cp /content/New_Dataset/validation/Warts/warts-common-17.jpg /content/

from keras.preprocessing import image

Sample_Image = image.load_img('warts-common-17.jpg', target_size=(224, 224))

plt.imshow(Sample_Image)

Sample_Image = tf.keras.preprocessing.image.img_to_array(Sample_Image)

Sample_Image = np.expand_dims(Sample_Image, axis = 0)
Sample_Image = tf.keras.applications.resnet50.preprocess_input(Sample_Image)
predictions = model.predict(Sample_Image)
print('Predictions:', predictions)

